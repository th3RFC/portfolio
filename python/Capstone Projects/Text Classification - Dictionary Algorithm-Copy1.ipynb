{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a607aa1f",
   "metadata": {},
   "source": [
    "# Text Classification: Dictionary Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609e3f99",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction: Custom Text Classification for Enhanced Data Insights](#Introduction)\n",
    "2. [Building the Algorithm](#Building-the-Algorithm)\n",
    "3. [Example: Dictionary](#Example-Dictionary)\n",
    "4. [Example: Individual Strings](#Example-Individual-Strings)\n",
    "5. [Example: Data Frame](#Example-Data-Frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ee2a5",
   "metadata": {},
   "source": [
    "## Introduction: Custom Text Classification for Enhanced Data Insights <a id=\"Introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3a9b1a",
   "metadata": {},
   "source": [
    "Welcome to this Jupyter notebook that embarks on an innovative journey in text analysis. Our focus here is not just on extracting key terms from text strings, but on elevating this process by assigning these terms to custom classifications that resonate with specific business contexts and use cases. In doing so, we transition from a generic clustering approach to a more targeted text classification methodology.\n",
    "\n",
    "### Shifting from Clustering to Custom Classification\n",
    "Traditional text clustering, an unsupervised machine learning method, often groups text in a manner that may not be directly meaningful or applicable in certain business scenarios. To counter this, we pivot to a supervised learning model, utilizing predefined categories that are more aligned with our specific objectives and contextual understanding.\n",
    "\n",
    "### The Code: A Synergy of Text Processing and Custom Mapping\n",
    "This notebook presents a comprehensive codebase that integrates several Python libraries and techniques:\n",
    "- **Libraries and Preprocessing**: Utilizing libraries like `pandas` for data manipulation, `nltk` for natural language processing, and standard tools for text normalization and preprocessing.\n",
    "- **Advanced Keyword Extraction**: Employing methods to extract not just individual words but also significant pairs (bigrams) and triples (trigrams) of words, adding depth to our analysis.\n",
    "- **Creating a Custom Dictionary**: We define a dictionary with keys representing our bespoke categories (like 'Environment', 'Technology', 'Sports') and values that are specific terms or phrases.\n",
    "- **Classification Algorithm**: Our custom function, `find_key_by_value`, processes text data to classify it under the most relevant category from our dictionary, based on the occurrence and relevance of keywords.\n",
    "- **Practical Application on Data**: We apply this function to real data, both on individual text strings and on a DataFrame, demonstrating its practical utility in assigning relevant topics to text data.\n",
    "\n",
    "### Objective and Conclusion\n",
    "The goal of this notebook is to provide a framework that transforms general text data into meaningful, context-specific classifications. By the end of this exploration, you will have a versatile tool for text analysis that not only offers insights tailored to specific business needs but also enhances the decision-making process with data that is classified in a more meaningful and contextually relevant manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef2c6be",
   "metadata": {},
   "source": [
    "## Building the Algorithm <a id=\"Building-the-Algorithm\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058e989a",
   "metadata": {},
   "source": [
    "### Essential Python Libraries for Dictionary Algorithm\n",
    "\n",
    "Before exploring this Dictionary Algorithm notebook, let's import the necessary Python libraries that will be pivotal in building this algorithm:\n",
    "\n",
    "- **`pandas`**: A foundational library in Python for data manipulation and analysis. It offers data structures and operations for manipulating numerical tables and time series, making it ideal for handling and analyzing large datasets, such as collections of text data.\n",
    "\n",
    "- **`nltk`**: The Natural Language Toolkit, a comprehensive library in Python for processing and analyzing human language data. It includes libraries for breaking texts down into their constituent parts, tagging them, identifying semantic information, and categorizing them.\n",
    "\n",
    "- **`nltk.corpus.stopwords`**: A module within NLTK specifically for accessing a collection of 'stop words'. Stop words are commonly used words (such as 'the', 'is', 'in') that are typically ignored in text processing and natural language understanding tasks because they carry minimal meaningful content.\n",
    "\n",
    "- **`string`**: This standard Python library is essential for handling and manipulating string data. It provides capabilities such as basic string formatting, constants, and utility functions, which are particularly useful for tasks like punctuation removal in text processing.\n",
    "\n",
    "- **`unicodedata`**: A Python module that provides access to the Unicode Character Database. In text processing, this is particularly useful for normalizing texts, ensuring consistent character representation across different text samples and encoding formats.\n",
    "\n",
    "- **`collections.Counter`**: Part of the Python collections module, `Counter` is a subclass of dictionary that's used for counting hashable objects. It's an ideal tool for keeping track of word frequencies in a text, which is a common requirement in various text analysis tasks.\n",
    "\n",
    "By importing these libraries at the beginning, we ensure that all the necessary tools are readily available for efficient and effective text analysis and processing. Each library plays a crucial role in handling different aspects of language data and data manipulation, ensuring a comprehensive approach to our text processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a64c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "import unittest\n",
    "import math\n",
    "\n",
    "# Set the display.max_colwidth option to -1 to display the full contents of columns\n",
    "pd.set_option('display.max_colwidth', None)  # or use -1 for older versions of pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9658861",
   "metadata": {},
   "source": [
    "### Enhanced Text Analysis for Keyword Extraction\n",
    "\n",
    "This Python code comprises three functions: `find_max_sequence_length`, `calculate_weight`, and `find_key_by_value`. Together, they offer a sophisticated method for extracting the most relevant keyword from a text based on a predefined dictionary of keywords.\n",
    "\n",
    "#### Function `find_max_sequence_length`\n",
    "\n",
    "- **Purpose**: Determines the maximum number of words in any phrase within the values of a given dictionary.\n",
    "- **Process**:\n",
    "  - Iterates through each value in the dictionary.\n",
    "  - Splits each phrase into words and counts the number.\n",
    "  - Keeps track of the maximum word count found.\n",
    "- **Usage**: Assists in dynamically determining the analysis depth for the input string in `find_key_by_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018e05c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_sequence_length(dictionary):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    dictionary (dict): A dictionary where each value is a list of strings (phrases).\n",
    "\n",
    "    Returns:\n",
    "    int: The maximum number of words found in any single phrase in the dictionary values.\n",
    "\n",
    "    Raises:\n",
    "    TypeError: If the input is not a dictionary or if the dictionary values are not lists.\n",
    "    ValueError: If any value in the dictionary is not a list of strings.\n",
    "    \"\"\"\n",
    "    if not isinstance(dictionary, dict):\n",
    "        raise TypeError(\"Input must be a dictionary.\")\n",
    "\n",
    "    max_length = 0\n",
    "    for values in dictionary.values():\n",
    "        if not all(isinstance(phrase, str) for phrase in values):\n",
    "            raise ValueError(\"All values in the dictionary must be lists of strings.\")\n",
    "\n",
    "        for phrase in values:\n",
    "            length = len(phrase.split())\n",
    "            max_length = max(max_length, length)\n",
    "\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f3ab200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.007s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2290f39ca90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestFindMaxSequenceLength(unittest.TestCase):\n",
    "    def test_empty_dictionary(self):\n",
    "        \"\"\"Test an empty dictionary.\"\"\"\n",
    "        self.assertEqual(find_max_sequence_length({}), 0)\n",
    "\n",
    "    def test_single_word_values(self):\n",
    "        \"\"\"Test a dictionary with single-word values.\"\"\"\n",
    "        dictionary = {'key1': ['word', 'another'], 'key2': ['test']}\n",
    "        self.assertEqual(find_max_sequence_length(dictionary), 1)\n",
    "\n",
    "    def test_multi_word_values(self):\n",
    "        \"\"\"Test a dictionary with multi-word values.\"\"\"\n",
    "        dictionary = {'key1': ['single word', 'two words'], 'key2': ['this is three', 'four word phrase']}\n",
    "        self.assertEqual(find_max_sequence_length(dictionary), 3)\n",
    "\n",
    "# Run the tests\n",
    "unittest.main(argv=[''], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1287f149",
   "metadata": {},
   "source": [
    "#### Function `calculate_weight`\n",
    "\n",
    "- **Purpose**: Provides a weighting mechanism for word combinations based on their length.\n",
    "- **Process**:\n",
    "  - Given the length of a word combination (e.g., single, pair, triple), calculates a weight.\n",
    "  - Uses a linear formula with a multiplier (0.5 by default) to ensure longer combinations have more influence, but in a balanced manner.\n",
    "- **Usage**: Used in `find_key_by_value` to weight matches according to their word count, giving preference to longer, more contextually rich matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b188660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weight(length, weight_factor=0.5):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    length (int): The length of the word sequence.\n",
    "    weight_factor (float, optional): The multiplier used to calculate the weight. Default is 0.5.\n",
    "\n",
    "    Returns:\n",
    "    float: The calculated weight for the given length.\n",
    "\n",
    "    Raises:\n",
    "    TypeError: If the input 'length' is not an integer or 'weight_factor' is not a float.\n",
    "    ValueError: If the 'length' is less than 1 or 'weight_factor' is negative.\n",
    "    \"\"\"\n",
    "    if not isinstance(length, int):\n",
    "        raise TypeError(\"Length must be an integer.\")\n",
    "\n",
    "    if length < 1:\n",
    "        raise ValueError(\"Length must be a positive integer.\")\n",
    "\n",
    "    if not isinstance(weight_factor, (float, int)):\n",
    "        raise TypeError(\"Weight factor must be a float or an integer.\")\n",
    "\n",
    "    if weight_factor < 0:\n",
    "        raise ValueError(\"Weight factor must be a non-negative number.\")\n",
    "\n",
    "    return 1 + (length - 1) * weight_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12e319a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.006s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2290f39cd90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestCalculateWeight(unittest.TestCase):\n",
    "    def test_single_word(self):\n",
    "        \"\"\"Test weight calculation for a single word.\"\"\"\n",
    "        self.assertEqual(calculate_weight(1), 1)\n",
    "\n",
    "    def test_pair(self):\n",
    "        \"\"\"Test weight calculation for a pair of words.\"\"\"\n",
    "        self.assertEqual(calculate_weight(2), 1.5)\n",
    "\n",
    "    def test_triple(self):\n",
    "        \"\"\"Test weight calculation for a triple of words.\"\"\"\n",
    "        self.assertEqual(calculate_weight(3), 2)\n",
    "\n",
    "    def test_longer_sequence(self):\n",
    "        \"\"\"Test weight calculation for a longer sequence.\"\"\"\n",
    "        self.assertEqual(calculate_weight(5), 3)\n",
    "\n",
    "# This will run the tests\n",
    "unittest.main(argv=[''], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab1a8a",
   "metadata": {},
   "source": [
    "#### Function `find_key_by_value`\n",
    "\n",
    "- **Inputs**: A string and a dictionary.\n",
    "- **Process**:\n",
    "  1. **Lowercase Conversion**: Converts the input string to lowercase for uniformity.\n",
    "  2. **Tokenization and Punctuation Removal**: Uses NLTK's `word_tokenize` to split the string into words, removing non-alphanumeric characters.\n",
    "  3. **Stop Words Removal**: Filters out common stop words (e.g., 'and', 'the', 'is') using NLTK's stopwords list.\n",
    "  4. **Determine Maximum Sequence Length**: Calls `find_max_sequence_length` to get the longest word sequence in the dictionary values.\n",
    "  5. **Generate Word Combinations**: Dynamically creates combinations of words (singles, pairs, triples, etc.) up to the maximum length.\n",
    "  6. **Search and Weight Matches in Dictionary**: For each combination, checks for matches in the dictionary values. Uses `calculate_weight` to apply appropriate weighting to each match.\n",
    "  7. **Count and Identify Most Common Key**: Uses a `Counter` to tally occurrences of each key, considering the weights, and identifies the most common key.\n",
    "- **Return**: The most common key if matches exist; otherwise, `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f212a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_key_by_value(string, dictionary):\n",
    "    # Convert string to lowercase\n",
    "    string = string.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    words = nltk.word_tokenize(string)\n",
    "    words = [word for word in words if word.isalnum()]\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Determine the maximum sequence length from the dictionary\n",
    "    max_length = find_max_sequence_length(dictionary)\n",
    "\n",
    "    # Generate combinations of words up to the maximum length\n",
    "    elements = []\n",
    "    for i in range(1, max_length + 1):\n",
    "        elements += [(i, \" \".join(words[j:j+i])) for j in range(len(words) - i + 1)]\n",
    "\n",
    "    matching_keys = []\n",
    "    for length, element in elements:\n",
    "        for key, value in dictionary.items():\n",
    "            if element in value:\n",
    "                weight = calculate_weight(length)\n",
    "                matching_keys += [key] * int(weight)  # Apply weighting function\n",
    "\n",
    "    counter = Counter(matching_keys)\n",
    "    if counter:\n",
    "        most_common = counter.most_common(1)\n",
    "        return most_common[0][0]\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09629ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 0.050s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2290f3c64c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestFindKeyByValue(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # Setup a sample dictionary for testing\n",
    "        self.sample_dict = {\n",
    "            'Environment': ['rainforest', 'climate change'],\n",
    "            'Technology': ['AI', 'machine learning'],\n",
    "            'Sports': ['football', 'teamwork']\n",
    "        }\n",
    "\n",
    "    def test_match_found(self):\n",
    "        \"\"\"Test a case where the match is found.\"\"\"\n",
    "        result = find_key_by_value(\"Advancements in machine learning\", self.sample_dict)\n",
    "        self.assertEqual(result, 'Technology')\n",
    "\n",
    "    def test_no_match_found(self):\n",
    "        \"\"\"Test a case where no match is found.\"\"\"\n",
    "        result = find_key_by_value(\"This is an unmatched string\", self.sample_dict)\n",
    "        self.assertIsNone(result)\n",
    "\n",
    "    def test_empty_string(self):\n",
    "        \"\"\"Test with an empty string.\"\"\"\n",
    "        result = find_key_by_value(\"\", self.sample_dict)\n",
    "        self.assertIsNone(result)\n",
    "\n",
    "    def test_empty_dictionary(self):\n",
    "        \"\"\"Test with an empty dictionary.\"\"\"\n",
    "        result = find_key_by_value(\"Some string\", {})\n",
    "        self.assertIsNone(result)\n",
    "\n",
    "# This will run the tests\n",
    "unittest.main(argv=[''], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9088fd",
   "metadata": {},
   "source": [
    "This methodology enhances text processing by removing extraneous elements and considering context through word combinations. It dynamically adapts to the dictionary's complexity and prioritizes longer, more meaningful word sequences in identifying the most relevant topic or category in the text. This is especially useful in tasks like keyword extraction and categorization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcdc01f",
   "metadata": {},
   "source": [
    "## Example: Dictionary <a id=\"Example-Dictionary\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e55bbe",
   "metadata": {},
   "source": [
    "### Topic-Specific Keyword Dictionary\n",
    "\n",
    "In our text analysis task, we use a specialized dictionary `my_dictionary` that contains key-value pairs for different topics. This dictionary is structured to help identify the central theme of a given text based on keyword and phrase matches. Each key in this dictionary represents a distinct topic, and the associated value is a list of keywords and key phrases relevant to that topic.\n",
    "\n",
    "- **`Environment`**: This key represents texts related to environmental issues. The associated value is a list of keywords such as 'rainforest', 'species', and phrases like 'climate change', 'diverse species'. These terms are specifically chosen to capture the essence of environmental discussions, focusing on biodiversity, ecological issues, and climate concerns.\n",
    "\n",
    "- **`Technology`**: Under this key, we group texts that discuss technological advancements. The keywords and phrases here include 'AI' (Artificial Intelligence), 'computing', 'machine learning', and 'advancements in'. These terms are pivotal in capturing discussions around modern technological innovations and trends, especially in the field of computing and AI.\n",
    "\n",
    "- **`Sports`**: This key is dedicated to sports-related texts. The list of keywords includes 'football', 'match', and phrases like 'teamwork', 'football match'. These are common terms in sports discussions, especially related to football, highlighting aspects of gameplay, team dynamics, and match events.\n",
    "\n",
    "By using this dictionary, we can analyze a text and determine which topic it most likely pertains to based on the occurrence of these predefined keywords and phrases. This approach is particularly useful in categorizing texts and extracting topic-specific insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0f49fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with key-value pairs for each topic\n",
    "my_dictionary = {\n",
    "    'Environment': ['rainforest', 'species', 'climate change', 'diverse species'],\n",
    "    'Technology': ['AI', 'computing', 'machine learning', 'advancements in'],\n",
    "    'Sports': ['football', 'match', 'teamwork', 'football match']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d1121b",
   "metadata": {},
   "source": [
    "## Example: Individual Strings <a id=\"Example-Individual-Strings\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824b55e5",
   "metadata": {},
   "source": [
    "### Preparing Test Strings for Topic Analysis\n",
    "\n",
    "To demonstrate the effectiveness of our text processing and categorization approach, we prepare a set of test strings. Each string is carefully crafted to represent a specific topic, corresponding to the keys in our `my_dictionary`. These strings serve as examples to showcase how our algorithm identifies the relevant topic based on the keywords and phrases in the text.\n",
    "\n",
    "- **`environment_string`**: This string focuses on environmental issues, specifically highlighting the rainforest's biodiversity and the threat of climate change. The sentence \"The rainforest is home to diverse species. Climate change threatens this habitat.\" is designed to include keywords like 'rainforest', 'diverse species', and 'climate change', which are pivotal for the 'Environment' category in our dictionary.\n",
    "\n",
    "- **`technology_string`**: Aimed at the theme of technology, this string encapsulates key elements of modern tech discourse. \"Advancements in AI and computing are transforming our world. Machine learning is key.\" includes terms such as 'AI', 'computing', and 'machine learning', aligning it with the 'Technology' category in our dictionary.\n",
    "\n",
    "- **`sports_string`**: This string is all about sports, with a focus on football. \"The football match was thrilling. Teamwork and strategy led to victory.\" includes specific references to a 'football match' and general sports themes like 'teamwork', making it a perfect fit for the 'Sports' category in our dictionary.\n",
    "\n",
    "By analyzing these strings using our `find_key_by_value` function and `my_dictionary`, we can effectively demonstrate how our text categorization system works, identifying the most relevant topic for each string based on its content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0073523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Strings\n",
    "environment_string = \"The rainforest is home to diverse species. Climate change threatens this habitat.\"\n",
    "technology_string = \"Advancements in AI and computing are transforming our world. Machine learning is key.\"\n",
    "sports_string = \"The football match was thrilling. Teamwork and strategy led to victory.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e8734",
   "metadata": {},
   "source": [
    "### Application of Text Categorization Function\n",
    "\n",
    "After setting up our test strings and keyword dictionary, the next step is to apply the `find_key_by_value` function to each string. This function analyzes the content of the strings and matches them with the most relevant topic based on our predefined keyword dictionary. The process and results are as follows:\n",
    "\n",
    "- **Applying to `environment_string`**: \n",
    "  - We pass the `environment_string` and `my_dictionary` to the `find_key_by_value` function. This string, themed around environmental issues, is analyzed to identify the most relevant topic based on the keywords it contains.\n",
    "  - The result is stored in `environment_result`.\n",
    "\n",
    "- **Applying to `technology_string`**: \n",
    "  - Similarly, the `technology_string` is processed using the same function. This string focuses on technology-related topics and is evaluated to find its best-matching category in the dictionary.\n",
    "  - The outcome is captured in `technology_result`.\n",
    "\n",
    "- **Applying to `sports_string`**: \n",
    "  - The `sports_string`, which revolves around a sports theme, particularly football, is also analyzed using the function. The aim is to determine its corresponding topic from the dictionary.\n",
    "  - This result is saved in `sports_result`.\n",
    "\n",
    "- **Printing the Results**:\n",
    "  - Finally, we print out the results for each string. This showcases which topic (Environment, Technology, or Sports) has been identified as the most relevant for each respective string based on the presence of specific keywords and phrases.\n",
    "  - The print statements display the outcomes in a format like \"Environment String Result: [Topic]\".\n",
    "\n",
    "By executing this code, we can observe the effectiveness of our keyword-based text categorization approach, demonstrating how the algorithm matches each string with the most fitting topic from our dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25e7483f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment String Result: Environment\n",
      "Technology String Result: Technology\n",
      "Sports String Result: Sports\n"
     ]
    }
   ],
   "source": [
    "# Applying the function to each test string\n",
    "environment_result = find_key_by_value(environment_string, my_dictionary)\n",
    "technology_result = find_key_by_value(technology_string, my_dictionary)\n",
    "sports_result = find_key_by_value(sports_string, my_dictionary)\n",
    "\n",
    "# Printing the results\n",
    "print(\"Environment String Result:\", environment_result)\n",
    "print(\"Technology String Result:\", technology_result)\n",
    "print(\"Sports String Result:\", sports_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f54bb",
   "metadata": {},
   "source": [
    "## Example:Data Frame <a id=\"Example-Data-Frame\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5ebd35",
   "metadata": {},
   "source": [
    "### Creating a DataFrame with Test Strings for Topic Analysis\n",
    "\n",
    "To effectively demonstrate our text categorization algorithm, we first create a pandas DataFrame. This DataFrame will contain a series of test strings, each specifically crafted to represent a different topic. This setup is essential for testing our algorithm's ability to accurately categorize text based on predefined keywords.\n",
    "\n",
    "In this below code snippet:\n",
    "\n",
    "- **Data Dictionary**: A dictionary named `data` is created with a key `text`. The value associated with this key is a list of strings, each a sentence relevant to a specific topic (Environment, Technology, and Sports).\n",
    "\n",
    "- **DataFrame Creation**: Using `pd.DataFrame(data)`, we convert this dictionary into a pandas DataFrame named `df`. This DataFrame now holds our test strings in a structured format, ideal for applying our text categorization function.\n",
    "\n",
    "The DataFrame `df` will serve as the foundation for applying our `find_key_by_value` function, allowing us to test and showcase the algorithm's capability to discern and categorize the topic of each string based on its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38b090f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with test strings\n",
    "data = {\n",
    "    'text': [\n",
    "        \"The rainforest is home to diverse species. Climate change threatens this habitat.\",\n",
    "        \"Advancements in AI and computing are transforming our world. Machine learning is key.\",\n",
    "        \"The football match was thrilling. Teamwork and strategy led to victory.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7314811",
   "metadata": {},
   "source": [
    "### Applying the Categorization Function to DataFrame\n",
    "\n",
    "After preparing our DataFrame with test strings, the next crucial step is to apply the `find_key_by_value` function to each row. This process involves analyzing the text in each row and categorizing it based on our predefined keyword dictionary. We also create a new column in the DataFrame to store these categorization results.\n",
    "\n",
    "This code does the following:\n",
    "\n",
    "- **Function Application**: The `apply` method is used on the 'text' column of the DataFrame `df`. For each row, the `find_key_by_value` function is called with the text as input and `my_dictionary` for keyword reference. This function determines the most relevant topic for each text string.\n",
    "\n",
    "- **Creating a New Column**: The results of the function application (i.e., the identified topics) are stored in a new column in the DataFrame named 'topic'.\n",
    "\n",
    "- **Displaying Results**: Finally, the updated DataFrame is printed. This DataFrame now includes both the original text strings and the corresponding topics identified by the algorithm.\n",
    "\n",
    "By executing this code, we demonstrate the capability of our text categorization algorithm to analyze each string and assign a relevant topic from our keyword dictionary. The result is a DataFrame that not only contains the original text but also a categorization of each text, reflecting the primary theme or topic it represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8ce0419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The rainforest is home to diverse species. Climate change threatens this habitat.</td>\n",
       "      <td>Environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advancements in AI and computing are transforming our world. Machine learning is key.</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The football match was thrilling. Teamwork and strategy led to victory.</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    text  \\\n",
       "0      The rainforest is home to diverse species. Climate change threatens this habitat.   \n",
       "1  Advancements in AI and computing are transforming our world. Machine learning is key.   \n",
       "2                The football match was thrilling. Teamwork and strategy led to victory.   \n",
       "\n",
       "         topic  \n",
       "0  Environment  \n",
       "1   Technology  \n",
       "2       Sports  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to each row and create a new column with the results\n",
    "df['topic'] = df['text'].apply(lambda x: find_key_by_value(x, my_dictionary))\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
